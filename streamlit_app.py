import streamlit as st
import google.generativeai as genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
import plotly.graph_objects as go
from PIL import Image
import io
import json
import os
import tempfile

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ“š ì´ˆë“±í•™ìƒ ì¼ê¸° í‰ê°€ ì±—ë´‡",
    page_icon="ğŸ“",
    layout="wide"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.3rem;
        color: #424242;
        margin-bottom: 1rem;
    }
    .evaluation-box {
        background-color: #E3F2FD;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
    .stChat message {
        border-radius: 15px;
    }
</style>
""", unsafe_allow_html=True)

# API í‚¤ ì„¤ì •
GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
genai.configure(api_key=GEMINI_API_KEY)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "messages" not in st.session_state:
    st.session_state.messages = []
if "vectorstore" not in st.session_state:
    st.session_state.vectorstore = None
if "qa_chain" not in st.session_state:
    st.session_state.qa_chain = None
if "extracted_text" not in st.session_state:
    st.session_state.extracted_text = ""
if "evaluation_result" not in st.session_state:
    st.session_state.evaluation_result = None


@st.cache_resource
def load_pdf_and_create_vectorstore():
    """PDF ë¡œë“œ ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±"""
    try:
        # PDF íŒŒì¼ ë¡œë“œ
        loader = PyPDFLoader("test.pdf")
        documents = loader.load()
        
        # í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        splits = text_splitter.split_documents(documents)
        
        # ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        embeddings = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            google_api_key=GEMINI_API_KEY
        )
        vectorstore = FAISS.from_documents(splits, embeddings)
        
        return vectorstore
    except Exception as e:
        st.error(f"PDF ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None


def create_qa_chain(vectorstore):
    """QA ì²´ì¸ ìƒì„±"""
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        google_api_key=GEMINI_API_KEY,
        temperature=0.3
    )
    
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True,
        output_key="answer"
    )
    
    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        memory=memory,
        return_source_documents=True
    )
    
    return qa_chain


def extract_text_from_image(image):
    """Gemini Visionì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    model = genai.GenerativeModel("gemini-2.5-flash")
    
    prompt = """ì´ ì´ë¯¸ì§€ëŠ” ì´ˆë“±í•™ìƒì´ ì“´ ì¼ê¸°ì…ë‹ˆë‹¤. 
    ì´ë¯¸ì§€ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
    ì†ê¸€ì”¨ë¥¼ ì£¼ì˜ ê¹Šê²Œ ì½ê³ , ì›ë¬¸ ê·¸ëŒ€ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
    ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•˜ì„¸ìš”."""
    
    response = model.generate_content([prompt, image])
    return response.text


def evaluate_diary(text, criteria):
    """ì¼ê¸° í‰ê°€ ìˆ˜í–‰"""
    model = genai.GenerativeModel("gemini-2.5-flash")
    
    prompt = f"""ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒ ì¼ê¸°ë¥¼ í‰ê°€í•˜ëŠ” ì „ë¬¸ êµì‚¬ì…ë‹ˆë‹¤.
    
ë‹¤ìŒ ì¼ê¸°ë¥¼ ì•„ë˜ í‰ê°€ ê¸°ì¤€ì— ë”°ë¼ í‰ê°€í•´ì£¼ì„¸ìš”.

[ì¼ê¸° ë‚´ìš©]
{text}

[í‰ê°€ ê¸°ì¤€]
{criteria}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "overall_score": 1-5 ì‚¬ì´ì˜ ìˆ«ì (ì¢…í•© ì ìˆ˜),
    "categories": [
        {{"name": "ë§ì¶¤ë²•/ë¬¸ë²•", "score": 1-5, "feedback": "í”¼ë“œë°±"}},
        {{"name": "ë‚´ìš© ì¶©ì‹¤ë„", "score": 1-5, "feedback": "í”¼ë“œë°±"}},
        {{"name": "í‘œí˜„ë ¥", "score": 1-5, "feedback": "í”¼ë“œë°±"}},
        {{"name": "êµ¬ì„±/íë¦„", "score": 1-5, "feedback": "í”¼ë“œë°±"}},
        {{"name": "ì°½ì˜ì„±", "score": 1-5, "feedback": "í”¼ë“œë°±"}}
    ],
    "overall_feedback": "ì „ì²´ì ì¸ í”¼ë“œë°±ê³¼ ê²©ë ¤ì˜ ë§",
    "improvement_tips": ["ê°œì„  ì œì•ˆ 1", "ê°œì„  ì œì•ˆ 2", "ê°œì„  ì œì•ˆ 3"]
}}

JSONë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""

    response = model.generate_content(prompt)
    
    # JSON íŒŒì‹±
    try:
        result_text = response.text.strip()
        # JSON ë¸”ë¡ ì¶”ì¶œ
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0]
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0]
        
        return json.loads(result_text)
    except json.JSONDecodeError:
        return None


def create_radar_chart(evaluation_result):
    """í‰ê°€ ê²°ê³¼ë¥¼ ë ˆì´ë” ì°¨íŠ¸ë¡œ ì‹œê°í™”"""
    categories = evaluation_result["categories"]
    
    names = [cat["name"] for cat in categories]
    scores = [cat["score"] for cat in categories]
    
    # ë ˆì´ë” ì°¨íŠ¸ ë‹«ê¸° ìœ„í•´ ì²« ë²ˆì§¸ ê°’ ì¶”ê°€
    names.append(names[0])
    scores.append(scores[0])
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatterpolar(
        r=scores,
        theta=names,
        fill='toself',
        fillcolor='rgba(30, 136, 229, 0.3)',
        line=dict(color='#1E88E5', width=2),
        name='í‰ê°€ ì ìˆ˜'
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 5],
                tickvals=[1, 2, 3, 4, 5],
                ticktext=['1ì ', '2ì ', '3ì ', '4ì ', '5ì ']
            )
        ),
        showlegend=False,
        title=dict(
            text="ğŸ“Š ì¼ê¸° í‰ê°€ ê²°ê³¼",
            font=dict(size=20)
        ),
        height=400
    )
    
    return fig


def create_pie_chart(evaluation_result):
    """í‰ê°€ ê²°ê³¼ë¥¼ ì›í˜• ê·¸ë˜í”„ë¡œ ì‹œê°í™”"""
    categories = evaluation_result["categories"]
    
    names = [cat["name"] for cat in categories]
    scores = [cat["score"] for cat in categories]
    
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']
    
    fig = go.Figure(data=[go.Pie(
        labels=names,
        values=scores,
        hole=0.4,
        marker=dict(colors=colors),
        textinfo='label+value',
        texttemplate='%{label}<br>%{value}ì ',
        hovertemplate='%{label}: %{value}ì <extra></extra>'
    )])
    
    fig.update_layout(
        title=dict(
            text="ğŸ¥§ í•­ëª©ë³„ ì ìˆ˜ ë¶„í¬",
            font=dict(size=20)
        ),
        height=400,
        annotations=[dict(
            text=f'ì¢…í•©<br>{evaluation_result["overall_score"]}ì ',
            x=0.5, y=0.5,
            font_size=20,
            showarrow=False
        )]
    )
    
    return fig


def create_bar_chart(evaluation_result):
    """í‰ê°€ ê²°ê³¼ë¥¼ ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ ì‹œê°í™”"""
    categories = evaluation_result["categories"]
    
    names = [cat["name"] for cat in categories]
    scores = [cat["score"] for cat in categories]
    
    colors = ['#FF6B6B' if s < 3 else '#FFEAA7' if s < 4 else '#96CEB4' for s in scores]
    
    fig = go.Figure(data=[go.Bar(
        x=names,
        y=scores,
        marker_color=colors,
        text=scores,
        textposition='outside'
    )])
    
    fig.update_layout(
        title=dict(
            text="ğŸ“ˆ í•­ëª©ë³„ ìƒì„¸ ì ìˆ˜",
            font=dict(size=20)
        ),
        yaxis=dict(range=[0, 5.5], title="ì ìˆ˜"),
        xaxis=dict(title="í‰ê°€ í•­ëª©"),
        height=400
    )
    
    return fig


# ë©”ì¸ í—¤ë”
st.markdown('<h1 class="main-header">ğŸ“š ì´ˆë“±í•™ìƒ ì¼ê¸° í‰ê°€ ì±—ë´‡</h1>', unsafe_allow_html=True)

# íƒ­ êµ¬ì„±
tab1, tab2 = st.tabs(["ğŸ“ ì¼ê¸° í‰ê°€", "ğŸ’¬ PDF ê¸°ë°˜ ì±—ë´‡"])

# ============ íƒ­ 1: ì¼ê¸° í‰ê°€ ============
with tab1:
    st.markdown("### ğŸ“· ì¼ê¸° ì´ë¯¸ì§€ ì—…ë¡œë“œ")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # ì´ë¯¸ì§€ ì…ë ¥ ë°©ì‹ ì„ íƒ
        input_method = st.radio(
            "ì´ë¯¸ì§€ ì…ë ¥ ë°©ì‹ ì„ íƒ",
            ["ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ“¸ ì¹´ë©”ë¼ ì´¬ì˜"],
            horizontal=True
        )
        
        image = None
        
        if input_method == "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ":
            uploaded_file = st.file_uploader(
                "ì¼ê¸° ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
                type=["png", "jpg", "jpeg"],
                help="ì´ˆë“±í•™ìƒì´ ì‘ì„±í•œ ì¼ê¸° ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
            )
            if uploaded_file:
                image = Image.open(uploaded_file)
                
        else:  # ì¹´ë©”ë¼ ì´¬ì˜
            camera_image = st.camera_input("ì¼ê¸°ë¥¼ ì´¬ì˜í•˜ì„¸ìš”")
            if camera_image:
                image = Image.open(camera_image)
        
        # ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°
        if image:
            st.image(image, caption="ì—…ë¡œë“œëœ ì¼ê¸°", use_container_width=True)
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë²„íŠ¼
            if st.button("ğŸ” í…ìŠ¤íŠ¸ ì¶”ì¶œ", type="primary", use_container_width=True):
                with st.spinner("í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘..."):
                    extracted = extract_text_from_image(image)
                    st.session_state.extracted_text = extracted
                    st.success("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")
    
    with col2:
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ í‘œì‹œ ë° ìˆ˜ì •
        st.markdown("### ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
        extracted_text = st.text_area(
            "ì¶”ì¶œëœ ì¼ê¸° ë‚´ìš© (ìˆ˜ì • ê°€ëŠ¥)",
            value=st.session_state.extracted_text,
            height=200,
            placeholder="ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤..."
        )
        
        # í‰ê°€ ê¸°ì¤€ ì…ë ¥
        st.markdown("### ğŸ“‹ í‰ê°€ ê¸°ì¤€ ì„¤ì •")
        default_criteria = """1. ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì´ ì •í™•í•œê°€?
2. í•˜ë£¨ì˜ ì¼ê³¼ê°€ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆëŠ”ê°€?
3. ìì‹ ì˜ ê°ì •ê³¼ ìƒê°ì´ ì˜ í‘œí˜„ë˜ì—ˆëŠ”ê°€?
4. ê¸€ì˜ ì‹œì‘, ì¤‘ê°„, ëì´ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ëŠ”ê°€?
5. ë…ì°½ì ì¸ í‘œí˜„ì´ë‚˜ ë¹„ìœ ê°€ ì‚¬ìš©ë˜ì—ˆëŠ”ê°€?"""
        
        criteria = st.text_area(
            "í‰ê°€ ê¸°ì¤€ì„ ì…ë ¥í•˜ì„¸ìš”",
            value=default_criteria,
            height=150,
            help="í‰ê°€í•  ê¸°ì¤€ì„ ììœ ë¡­ê²Œ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        # í‰ê°€ ì‹¤í–‰ ë²„íŠ¼
        if st.button("âœ¨ ì¼ê¸° í‰ê°€í•˜ê¸°", type="primary", use_container_width=True):
            if extracted_text.strip():
                with st.spinner("ì¼ê¸°ë¥¼ í‰ê°€í•˜ëŠ” ì¤‘..."):
                    result = evaluate_diary(extracted_text, criteria)
                    if result:
                        st.session_state.evaluation_result = result
                        st.success("í‰ê°€ ì™„ë£Œ!")
                    else:
                        st.error("í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("ë¨¼ì € í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê±°ë‚˜ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # í‰ê°€ ê²°ê³¼ í‘œì‹œ
    if st.session_state.evaluation_result:
        st.markdown("---")
        st.markdown("## ğŸ“Š í‰ê°€ ê²°ê³¼")
        
        result = st.session_state.evaluation_result
        
        # ì¢…í•© ì ìˆ˜ í‘œì‹œ
        score_col1, score_col2, score_col3 = st.columns([1, 2, 1])
        with score_col2:
            overall = result["overall_score"]
            stars = "â­" * overall
            st.markdown(f"""
            <div style="text-align: center; padding: 2rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white;">
                <h2>ì¢…í•© ì ìˆ˜</h2>
                <h1 style="font-size: 4rem;">{overall}/5</h1>
                <p style="font-size: 2rem;">{stars}</p>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("")
        
        # ì°¨íŠ¸ í‘œì‹œ
        chart_col1, chart_col2 = st.columns(2)
        
        with chart_col1:
            pie_chart = create_pie_chart(result)
            st.plotly_chart(pie_chart, use_container_width=True)
        
        with chart_col2:
            radar_chart = create_radar_chart(result)
            st.plotly_chart(radar_chart, use_container_width=True)
        
        # ë§‰ëŒ€ ê·¸ë˜í”„
        bar_chart = create_bar_chart(result)
        st.plotly_chart(bar_chart, use_container_width=True)
        
        # ìƒì„¸ í”¼ë“œë°±
        st.markdown("### ğŸ’¬ ìƒì„¸ í”¼ë“œë°±")
        
        for cat in result["categories"]:
            score = cat["score"]
            color = "#96CEB4" if score >= 4 else "#FFEAA7" if score >= 3 else "#FF6B6B"
            
            with st.expander(f"{cat['name']} - {score}ì  {'â­' * score}", expanded=True):
                st.markdown(f"""
                <div style="padding: 1rem; background-color: {color}20; border-left: 4px solid {color}; border-radius: 5px;">
                    {cat['feedback']}
                </div>
                """, unsafe_allow_html=True)
        
        # ì „ì²´ í”¼ë“œë°±
        st.markdown("### ğŸŒŸ ì„ ìƒë‹˜ì˜ í•œë§ˆë””")
        st.info(result["overall_feedback"])
        
        # ê°œì„  ì œì•ˆ
        st.markdown("### ğŸ’¡ ë” ì¢‹ì€ ì¼ê¸°ë¥¼ ìœ„í•œ íŒ")
        for i, tip in enumerate(result.get("improvement_tips", []), 1):
            st.markdown(f"**{i}.** {tip}")


# ============ íƒ­ 2: PDF ê¸°ë°˜ ì±—ë´‡ ============
with tab2:
    st.markdown("### ğŸ“– PDF ë¬¸ì„œ ê¸°ë°˜ Q&A ì±—ë´‡")
    
    # ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™”
    if st.session_state.vectorstore is None:
        with st.spinner("PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘..."):
            st.session_state.vectorstore = load_pdf_and_create_vectorstore()
            if st.session_state.vectorstore:
                st.session_state.qa_chain = create_qa_chain(st.session_state.vectorstore)
                st.success("PDF ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ!")
            else:
                st.warning("test.pdf íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    chat_container = st.container()
    
    with chat_container:
        # ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            if st.session_state.qa_chain:
                with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                    try:
                        response = st.session_state.qa_chain({
                            "question": prompt,
                            "chat_history": st.session_state.chat_history
                        })
                        
                        answer = response["answer"]
                        st.markdown(answer)
                        
                        # ì¶œì²˜ í‘œì‹œ
                        if response.get("source_documents"):
                            with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ"):
                                for i, doc in enumerate(response["source_documents"], 1):
                                    st.markdown(f"**ì¶œì²˜ {i}:** {doc.page_content[:200]}...")
                        
                        # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
                        st.session_state.chat_history.append((prompt, answer))
                        st.session_state.messages.append({"role": "assistant", "content": answer})
                        
                    except Exception as e:
                        error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                        st.error(error_msg)
                        st.session_state.messages.append({"role": "assistant", "content": error_msg})
            else:
                msg = "PDF íŒŒì¼ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. test.pdf íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                st.warning(msg)
                st.session_state.messages.append({"role": "assistant", "content": msg})
    
    # ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.chat_history = []
        st.rerun()

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.markdown("## â„¹ï¸ ì‚¬ìš© ì•ˆë‚´")
    
    st.markdown("""
    ### ğŸ“ ì¼ê¸° í‰ê°€ íƒ­
    1. **ì´ë¯¸ì§€ ì—…ë¡œë“œ** ë˜ëŠ” **ì¹´ë©”ë¼ ì´¬ì˜**ìœ¼ë¡œ ì¼ê¸° ì´ë¯¸ì§€ ì…ë ¥
    2. **í…ìŠ¤íŠ¸ ì¶”ì¶œ** ë²„íŠ¼ìœ¼ë¡œ ê¸€ì”¨ ì¸ì‹
    3. í•„ìš”ì‹œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ìˆ˜ì •
    4. **í‰ê°€ ê¸°ì¤€** ì„¤ì • (ê¸°ë³¸ê°’ ì œê³µ)
    5. **ì¼ê¸° í‰ê°€í•˜ê¸°** ë²„íŠ¼ìœ¼ë¡œ í‰ê°€ ì‹¤í–‰
    
    ### ğŸ’¬ ì±—ë´‡ íƒ­
    - test.pdf ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€
    - RAG ê¸°ìˆ ì„ í™œìš©í•œ ì •í™•í•œ ë‹µë³€ ì œê³µ
    
    ---
    
    ### â­ í‰ê°€ ì ìˆ˜ ê¸°ì¤€
    - **5ì **: ë§¤ìš° ìš°ìˆ˜
    - **4ì **: ìš°ìˆ˜
    - **3ì **: ë³´í†µ
    - **2ì **: ë…¸ë ¥ í•„ìš”
    - **1ì **: ë§ì€ ë…¸ë ¥ í•„ìš”
    """)
    
    st.markdown("---")
    st.markdown("ğŸ¤– Powered by **Gemini 2.5 Flash**")
